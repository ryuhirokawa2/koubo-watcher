import os
import requests
from bs4 import BeautifulSoup
from datetime import datetime

DISCORD_WEBHOOK = os.environ.get("DISCORD_WEBHOOK")

KEYWORDS = [
    "éŸ³æ¥½ å…¬å‹Ÿ",
    "æ¥½æ›² å‹Ÿé›†",
    "ä½œæ›² å‹Ÿé›†",
    "ã‚µã‚¦ãƒ³ãƒ‰ å‹Ÿé›†"
]

EXCLUDE_KEYWORDS = [
    "BMS",
    "BMSON",
    "BMSã‚¤ãƒ™ãƒ³ãƒˆ"
]

SOURCES = {
    "KONAMI": [
        "https://www.konami.com/games/event/",
        "https://www.konami.com/amusement/"
    ],
    "SEGA": [
        "https://www.sega.jp/topics/",
        "https://www.sega.co.jp/recruit/"
    ],
    "X": [
        "https://nitter.net/search?f=tweets&q=éŸ³ã‚²ãƒ¼+å…¬å‹Ÿ",
        "https://nitter.net/search?f=tweets&q=æ¥½æ›²+å‹Ÿé›†+éŸ³ã‚²ãƒ¼"
    ],
    "Threads": [
        "https://www.threads.net/search?q=éŸ³ã‚²ãƒ¼ å…¬å‹Ÿ"
    ],
    "Bluesky": [
        "https://bsky.app/search?q=éŸ³ã‚²ãƒ¼ å…¬å‹Ÿ"
    ]
}

def fetch(url):
    try:
        r = requests.get(url, timeout=15)
        r.raise_for_status()
        return r.text
    except Exception:
        return None

def is_valid(text):
    for ex in EXCLUDE_KEYWORDS:
        if ex.lower() in text.lower():
            return False
    for kw in KEYWORDS:
        if kw.lower() in text.lower():
            return True
    return False

def notify(title, url, source):
    content = (
        f"ğŸ® **ACéŸ³ã‚²ãƒ¼ å…¬å‹Ÿæƒ…å ±ã‚’æ¤œå‡ºï¼**\n\n"
        f"**{title}**\n"
        f"ğŸ“ Source: {source}\n"
        f"ğŸ”— {url}\n\n"
        f"ğŸ—‚ Notionç”¨ãƒªãƒ³ã‚¯: {url}\n"
        f"â° æ¤œå‡ºæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M')}"
    )

    requests.post(
        DISCORD_WEBHOOK,
        json={"content": content}
    )

def scan():
    for source, urls in SOURCES.items():
        for url in urls:
            html = fetch(url)
            if not html:
                continue

            soup = BeautifulSoup(html, "html.parser")
            links = soup.find_all("a")

            for a in links:
                title = a.get_text(strip=True)
                href = a.get("href")

                if not title or not href:
                    continue

                if not href.startswith("http"):
                    href = url.rstrip("/") + "/" + href.lstrip("/")

                text_blob = f"{title} {href}"

                if is_valid(text_blob):
                    notify(title, href, source)

if __name__ == "__main__":
    scan()
